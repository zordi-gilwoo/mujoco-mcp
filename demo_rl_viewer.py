#!/usr/bin/env python3
"""
Demo script showing RL Environment Viewer integration
This demonstrates the complete workflow from prompt to execution
"""

import os
import sys
import asyncio

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from mujoco_mcp.rl_integration import create_reaching_env, create_balancing_env
from mujoco_mcp.rl_runner import rl_runner


def demonstrate_rl_environment_parsing():
    """Demonstrate how RL prompts are parsed into environments"""
    print("üß† RL Environment Parsing Demo")
    print("=" * 40)
    
    # Simulate the parsing logic from our JavaScript
    test_prompts = [
        "Create a reaching task for Franka Panda to reach random targets with continuous actions",
        "Design a cart-pole balancing environment with discrete actions",
        "Build a quadruped walking environment with gait rewards",
        "Create a simple 2-DOF arm reaching task with sparse rewards"
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\n{i}. Prompt: {prompt}")
        
        # Parse prompt (same logic as JavaScript)
        config = {
            'task_type': 'reaching',
            'robot_type': 'simple_arm',  
            'action_space_type': 'continuous',
            'max_episode_steps': 1000,
            'reward_scale': 1.0
        }
        
        prompt_lower = prompt.lower()
        
        # Detect task type
        if 'reach' in prompt_lower:
            config['task_type'] = 'reaching'
        elif 'balanc' in prompt_lower:
            config['task_type'] = 'balancing'
        elif 'walk' in prompt_lower:
            config['task_type'] = 'walking'
        
        # Detect robot type
        if 'franka' in prompt_lower or 'panda' in prompt_lower:
            config['robot_type'] = 'franka_panda'
        elif 'cart' in prompt_lower and 'pole' in prompt_lower:
            config['robot_type'] = 'cart_pole'
        elif 'quadruped' in prompt_lower:
            config['robot_type'] = 'quadruped'
        elif 'simple' in prompt_lower and 'arm' in prompt_lower:
            config['robot_type'] = 'simple_arm'
        
        # Detect action space
        if 'discrete' in prompt_lower:
            config['action_space_type'] = 'discrete'
        elif 'continuous' in prompt_lower:
            config['action_space_type'] = 'continuous'
        
        print(f"   ‚Üí Task: {config['task_type']}")
        print(f"   ‚Üí Robot: {config['robot_type']}")
        print(f"   ‚Üí Actions: {config['action_space_type']}")


def generate_python_code_example(config):
    """Generate Python RL environment code (same as JavaScript)"""
    return f'''#!/usr/bin/env python3
"""
Auto-generated RL Environment for {config['task_type']} task with {config['robot_type']}
Generated by MuJoCo MCP Remote Viewer
"""

import numpy as np
import gymnasium as gym
from gymnasium import spaces
import time
from mujoco_mcp.rl_integration import MuJoCoRLEnvironment, RLConfig

def create_environment():
    """Create and return the RL environment"""
    config = RLConfig(
        robot_type="{config['robot_type']}",
        task_type="{config['task_type']}",
        max_episode_steps={config['max_episode_steps']},
        action_space_type="{config['action_space_type']}",
        reward_scale={config['reward_scale']}
    )
    return MuJoCoRLEnvironment(config)

def run_random_actions(env, num_steps=1000):
    """Run the environment with random actions"""
    print(f"ü§ñ Running {config['task_type']} task with random actions...")
    print(f"üìä Environment: {config['robot_type']}")
    print(f"üéÆ Action space: {config['action_space_type']}")
    print("=" * 50)
    
    obs, info = env.reset()
    total_reward = 0
    
    for step in range(num_steps):
        # Sample random action
        action = env.action_space.sample()
        
        # Execute action
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        
        # Print progress every 100 steps
        if step % 100 == 0:
            print(f"Step {{step:4d}}: reward={{reward:.3f}}, total={{total_reward:.3f}}")
        
        # Reset if episode ends
        if terminated or truncated:
            print(f"Episode finished at step {{step}}")
            obs, info = env.reset()
            total_reward = 0
        
        # Small delay for visualization
        time.sleep(0.01)
    
    print(f"‚úÖ Completed {{num_steps}} steps")

if __name__ == "__main__":
    # Create environment
    env = create_environment()
    
    print(f"Environment created successfully!")
    print(f"Observation space: {{env.observation_space}}")
    print(f"Action space: {{env.action_space}}")
    
    try:
        # Run with random actions
        run_random_actions(env, num_steps=1000)
    finally:
        env.close()
'''


async def demonstrate_environment_execution():
    """Demonstrate actual RL environment execution"""
    print("\nüöÄ RL Environment Execution Demo")
    print("=" * 42)
    
    # Test different environment types
    environments = [
        {
            'name': 'Simple Arm Reaching',
            'config': {
                'robot_type': 'simple_arm',
                'task_type': 'reaching',
                'max_episode_steps': 50,
                'action_space_type': 'continuous'
            }
        },
        {
            'name': 'Cart-Pole Balancing',
            'config': {
                'robot_type': 'cart_pole',
                'task_type': 'balancing',
                'max_episode_steps': 100,
                'action_space_type': 'discrete'
            }
        }
    ]
    
    for env_info in environments:
        print(f"\n--- {env_info['name']} ---")
        
        # Create environment
        if await rl_runner.create_environment(env_info['config']):
            print("‚úÖ Environment created")
            
            # Get initial status
            status = rl_runner.get_status()
            print(f"   Type: {status['environment_type']}")
            
            # Run briefly with random actions
            if await rl_runner.start_random_actions(num_steps=20, step_delay=0.001):
                print("üéÆ Running random actions...")
                
                # Let it run
                await asyncio.sleep(0.5)
                
                # Check progress
                status = rl_runner.get_status()
                print(f"   Completed {status['total_steps']} steps")
                print(f"   Total reward: {status['total_reward']:.3f}")
                
                # Stop
                await rl_runner.stop_environment()
                print("‚èπÔ∏è  Stopped")
            
            # Cleanup
            rl_runner.cleanup()
        else:
            print("‚ùå Failed to create environment")


def print_viewer_features():
    """Print summary of viewer features implemented"""
    print("\nüéØ RL Environment Viewer Features")
    print("=" * 42)
    
    features = [
        "‚úÖ Text prompt for creating RL environments",
        "‚úÖ Dropdown with predefined RL environment examples:",
        "   ‚Ä¢ Franka Panda Reaching Task",
        "   ‚Ä¢ Cart-Pole Balancing", 
        "   ‚Ä¢ Quadruped Walking",
        "   ‚Ä¢ Simple Arm Reaching",
        "‚úÖ Structural guidelines for RL environment creation",
        "‚úÖ Tab system in XML editor showing:",
        "   ‚Ä¢ Generated MuJoCo XML",
        "   ‚Ä¢ Python gymnasium environment code", 
        "‚úÖ Live editing capability for environments",
        "‚úÖ 'Run Random Actions' button for execution",
        "‚úÖ Real-time status monitoring",
        "‚úÖ Event logging and progress tracking",
        "‚úÖ Integration with existing MuJoCo viewer"
    ]
    
    for feature in features:
        print(feature)
    
    print("\nüìã Supported Environment Types:")
    env_types = [
        "‚Ä¢ Franka Panda (franka_panda) - 7-DOF robotic arm",
        "‚Ä¢ Cart-Pole (cart_pole) - Classic balancing task",
        "‚Ä¢ Quadruped (quadruped) - 4-legged walking robot",
        "‚Ä¢ Simple Arm (simple_arm) - 2-DOF robotic arm"
    ]
    
    for env_type in env_types:
        print(env_type)
    
    print("\nüéÆ Task Types:")
    task_types = [
        "‚Ä¢ Reaching - Move end-effector to target position",
        "‚Ä¢ Balancing - Maintain system stability", 
        "‚Ä¢ Walking - Locomotion and gait control",
        "‚Ä¢ Manipulation - Object interaction tasks"
    ]
    
    for task_type in task_types:
        print(task_type)


async def main():
    """Main demo function"""
    print("ü§ñ MuJoCo MCP RL Environment Viewer Demo")
    print("=" * 50)
    print("This demo shows the complete RL environment workflow:")
    print("1. Prompt parsing and environment generation")
    print("2. Code generation (XML + Python)")
    print("3. Environment execution with random actions")
    print("4. Integration with MuJoCo viewer")
    
    # Demonstrate prompt parsing
    demonstrate_rl_environment_parsing()
    
    # Show code generation example
    print("\nüíª Generated Python Code Example")
    print("=" * 40)
    config = {
        'task_type': 'reaching',
        'robot_type': 'franka_panda', 
        'action_space_type': 'continuous',
        'max_episode_steps': 1000,
        'reward_scale': 1.0
    }
    print("Sample generated code (truncated):")
    code = generate_python_code_example(config)
    print(code[:500] + "...\n# (truncated)")
    
    # Demonstrate actual execution
    await demonstrate_environment_execution()
    
    # Print feature summary
    print_viewer_features()
    
    print("\nüéâ Demo completed! The RL Environment Viewer is ready to use.")
    print("   Open client/index.html in a browser to try the interactive interface.")


if __name__ == "__main__":
    asyncio.run(main())